{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50390029",
   "metadata": {},
   "source": [
    "# Homework — GEIM and Data Assimilation (v2)\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "This homework explores the **Generalized Empirical Interpolation Method (GEIM)** for:\n",
    "- Building sensor dictionaries with different linear functionals\n",
    "- Greedy basis construction with simultaneous sensor selection\n",
    "- Data assimilation from sparse measurements\n",
    "- Stability analysis (Lebesgue constants, conditioning)\n",
    "- Robustness to noise via overdetermination and regularization\n",
    "\n",
    "**Key concepts:** Linear functionals, greedy algorithms, interpolation theory, least squares, Tikhonov regularization.\n",
    "\n",
    "**Tools:** NumPy for numerics, Matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3d9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d59b9",
   "metadata": {},
   "source": [
    "## 1. Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad533dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nq = 800\n",
    "x = np.linspace(0.0, 1.0, Nq)\n",
    "mu_box = np.array([[0.0,2.0],[0.0,2.0],[0.2,0.8]])\n",
    "def s_fun(x, mu):\n",
    "    mu1,mu2,mu3 = mu\n",
    "    return (1+mu1)*np.sin((1+mu2)*np.pi*x) + np.exp(-20.0*(x-mu3)**2)\n",
    "def sample_mu(n):\n",
    "    u = np.random.rand(n,3)\n",
    "    return mu_box[:,0] + u*(mu_box[:,1]-mu_box[:,0])\n",
    "n_train, n_test = 300, 150\n",
    "mu_train, mu_test = sample_mu(n_train), sample_mu(n_test)\n",
    "assert mu_train.shape==(n_train,3) and mu_test.shape==(n_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56874fc4",
   "metadata": {},
   "source": [
    "## 2. Sensor dictionary $A$\n",
    "TODO: implement Dirac-like probes (subsampled), box averages, Gaussian sensors; normalize rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11547273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(x, stride=10, n_boxes=16, box_width=0.06, n_gauss=16, sigma=0.035):\n",
    "    # --- TODO ---\n",
    "    raise NotImplementedError('make_dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b08af7",
   "metadata": {},
   "source": [
    "### Utility: forward substitution (unit diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_solve(L, b):\n",
    "    # --- TODO ---\n",
    "    raise NotImplementedError('forward_solve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0874b",
   "metadata": {},
   "source": [
    "## 3. GEIM offline (greedy)\n",
    "\n",
    "**GEIM idea.** Build basis functions $\\{\\rho_j\\}$ and a set of **sensors** $\\{L_i\\}$ such that\n",
    "$$ L_i\\big(I_M g\\big) = L_i(g), \\quad i=1,\\dots,M, $$\n",
    "with $I_M g(x) = \\sum_{j=1}^M \\gamma_j(\\mu)\\,\\rho_j(x)$ and the interpolation matrix $B_M = [L_i(\\rho_j)]$ **lower‑triangular with ones on the diagonal** (by normalization).\n",
    "\n",
    "**Task B.** Implement the GEIM greedy algorithm:\n",
    "1. Precompute training snapshots `S` on the grid for `mu_train`.\n",
    "2. **Select** $\\mu_1$ maximizing $\\|g(\\cdot;\\mu)\\|_\\infty$; set $\\xi_1=g(\\cdot;\\mu_1)$. **Choose** $L_1$ maximizing $|L(\\xi_1)|$ over the dictionary and set $\\rho_1=\\xi_1 / L_1(\\xi_1)$.\n",
    "3. For $m=1,\\dots,M-1$:\n",
    "   - Pick $\\mu_{m+1}$ maximizing the current interpolation error $\\|g-I_m g\\|_\\infty$ over the training set.\n",
    "   - Compute the residual $r_{m+1}=\\xi_{m+1}-I_m\\xi_{m+1}$.\n",
    "   - **Choose** $L_{m+1}$ in the dictionary (not yet used) maximizing $|L(r_{m+1})|$.\n",
    "   - Set $\\rho_{m+1}=r_{m+1}/L_{m+1}(r_{m+1})$.\n",
    "\n",
    "Store: `Q` ($N_q\\times M$), sensor indices list `J` (rows of `A`), selected training parameters, training errors, and (optionally) a discrete Lebesgue constant.\n",
    "\n",
    "*Hints.*\n",
    "- To reconstruct a snapshot with current $(Q_m, J_m)$: build $B_m=A[J_m,:]@Q_m$, measure $g_I=A[J_m,:]@g$, solve $\\gamma=\\text{forward\\_solve}(B_m, g_I)$, then `approx = Q_m @ gamma`.\n",
    "- With the normalization above, `B_m` is lower‑triangular with a unit diagonal by construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc54a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GEIMModel:\n",
    "    Q: np.ndarray\n",
    "    J: list\n",
    "    mu_sel: list\n",
    "    train_err: list\n",
    "    lebesgue: list\n",
    "\n",
    "def geim_offline(s_fun, x, mu_train, A, M_max=16, tol=1e-6):\n",
    "    # --- TODO ---\n",
    "    raise NotImplementedError('geim_offline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc03434",
   "metadata": {},
   "source": [
    "## 4. GEIM online (assimilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc36e8",
   "metadata": {},
   "source": [
    "\n",
    "**Task C.** Given `model` and a set of sensor measurements `y` at the selected sensors (rows `J`), reconstruct the field $g_M$ by solving\n",
    "$$ B_M\\,\\gamma = y, \\quad B_M = A[J,:]@Q, \\quad g_M = Q\\,\\gamma. $$\n",
    "Return `(gM, gamma)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geim_online(model, A, y):\n",
    "    # --- TODO ---\n",
    "    raise NotImplementedError('geim_online')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5f1f4",
   "metadata": {},
   "source": [
    "## 5. Sanity checks (after offline/online)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a6cc5",
   "metadata": {},
   "source": [
    "Check triangularity/unit diagonal of B=A[J,:]@Q and interpolation at selected sensors. \n",
    "\n",
    "After you implement `make_dictionary` and `geim_offline`, build a model with `M_max≈20` and verify:\n",
    "- `B = A[J,:] @ Q` is lower‑triangular with (approximately) unit diagonal.\n",
    "- Interpolation holds at selected sensors on the training snapshots: `A[J,:] @ (Q @ gamma) == A[J,:] @ g` for all training `g` when `gamma` solves `B gamma = A[J,:] @ g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2220a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = make_dictionary(x)\n",
    "# model = geim_offline(s_fun, x, mu_train, A, M_max=16, tol=1e-8)\n",
    "# B = A[model.J,:] @ model.Q\n",
    "# assert np.allclose(np.tril(B), B)\n",
    "# assert np.allclose(np.diag(B), 1.0, atol=1e-12)\n",
    "# S_train = np.stack([s_fun(x, mu) for mu in mu_train], axis=1)\n",
    "# rhs = A[model.J,:] @ S_train\n",
    "# gamma = forward_solve(B, rhs)\n",
    "# interp = model.Q @ gamma\n",
    "# assert np.allclose(A[model.J,:] @ interp, rhs, atol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81eb8e",
   "metadata": {},
   "source": [
    "## 6. Data assimilation: noise-free"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071238ed",
   "metadata": {},
   "source": [
    "**Task D.** Pick a fresh parameter `mu0`, generate measurements `y = A[J,:] @ s_fun(x, mu0)`, reconstruct with `geim_online`, and report the sup‑norm error `||truth - gM||_∞`. Plot the truth vs reconstruction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4065b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu0 = sample_mu(1)[0]\n",
    "# truth = s_fun(x, mu0)\n",
    "# y = (A[model.J,:] @ truth)\n",
    "# gM, _ = geim_online(model, A, y)\n",
    "# print('sup error (noise-free):', float(np.max(np.abs(truth-gM))))\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.plot(x, truth, label='truth')\n",
    "# plt.plot(x, gM, '--', label='GEIM')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7becf0b",
   "metadata": {},
   "source": [
    "## 7. Data assimilation: noisy and gappy (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261d386",
   "metadata": {},
   "source": [
    "Add i.i.d. Gaussian noise of level `sigma_y` to the measurements: `y^δ = y + δ`. Run multiple trials and compute the mean and standard deviation of the reconstruction error.\n",
    "\n",
    "**Task E (deterministic GEIM).** Repeat Task D with noisy measurements (same $M$). Study sensitivity as a function of (i) $M$, and (ii) the conditioning of $B_M$.\n",
    "\n",
    "**Task F (gappy‑GEIM: overdetermined).** Use **more sensors than basis functions** (|I| > M). Solve the least‑squares problem\n",
    "$$\\min_\\gamma \\; \\|A[I,:]Q\\,\\gamma - y^\\delta\\|_2^2 + \\tau\\,\\|\\gamma\\|_2^2,$$\n",
    "for some Tikhonov parameter $\\tau \\ge 0$. Compare errors vs the square case. *Hint:* use the normal equations or `np.linalg.lstsq` when $\\tau=0$; with Tikhonov, solve $(B^TB+\\tau I)\\gamma=B^Ty$ with $B=A[I,:]Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geim_online_gappy(Q, A, I_rows, y, tau=0.0):\n",
    "    # --- OPTIONAL TODO ---\n",
    "    raise NotImplementedError('geim_online_gappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9dd05",
   "metadata": {},
   "source": [
    "## 8. Diagnostics\n",
    "TODO: test-set sup error vs M; discrete Lebesgue constants; cond(B_m). **Task G.**\n",
    "1) **Test‑set error curve**: for each $m=1,\\dots,M$, reconstruct all test functions from measurements at the first $m$ sensors, and report $\\max_{x,\\mu\\in\\text{test}}|s-I_m s|$.\n",
    "2) **Discrete Lebesgue constant** (GEIM): compute $\\Lambda_m = \\max_x \\sum_i |(Q_m B_m^{-1})[x,i]|$ where $B_m=A[J_m,:]Q_m$. Plot growth of $\\Lambda_m$.\n",
    "3) **Conditioning**: plot $\\kappa(B_m)$ vs $m$. Relate error sensitivity to $\\Lambda_m$ and $\\kappa(B_m)$.\n",
    "\n",
    "*Hints:* These are identical to the EIM algebra with $Q$ and $B$ redefined using functionals. Compare with the lecture’s EIM error analysis and a posteriori one‑point result (you can define a “one‑functional estimator” by evaluating at the next chosen functional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ae50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_error_curve_geim(model, x, mu_test, A):\n",
    "#     # --- TODO ---\n",
    "#     raise NotImplementedError()\n",
    "#\n",
    "# def discrete_lebesgue_constants_geim(Q, J, A):\n",
    "#     # --- TODO ---\n",
    "#     raise NotImplementedError()\n",
    "#\n",
    "# def cond_numbers_geim(Q, J, A):\n",
    "#     # --- TODO ---\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb74be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
